{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIM\n",
    "\n",
    "Get familiar with sequence-to-sequence language modeling, specifically using an encoder-decoder model\n",
    "\n",
    "### Overview\n",
    "\n",
    "1. run with the E2E restaurant data set\n",
    "2. train a model on this dataset on a GPU\n",
    "3. implement beam search for evaluation\n",
    "4. implement a BLEU evaluator and report BLEU scores\n",
    "\n",
    "### 1. E2E Dataset\n",
    "\n",
    "In this dataset, the inputs are restaurant meaning representations, which are a series of key-value pairs that encode information about a restaurant. The outputs are fluent sentences that describe the restaurant.\n",
    "\n",
    "*Input: Meaning Representation*\n",
    "\n",
    "```\n",
    "name[The Eagle],\n",
    "eatType[coffee shop],\n",
    "food[French],\n",
    "priceRange[moderate],\n",
    "customerRating[3/5],\n",
    "area[riverside],\n",
    "kidsFriendly[yes],\n",
    "near[Burger King]\n",
    "```\n",
    "\n",
    "*Output: Fluent Sentence*\n",
    "\n",
    "```\n",
    "The three star coffee shop, The Eagle, gives families a mid-priced dining experience featuring a variety of wines and cheeses. Find The Eagle near Burger King.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mydevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_TOKEN = '<sos>'\n",
    "EOS_TOKEN = '<eos>'\n",
    "\n",
    "MAX_LEN = 50\n",
    "\n",
    "def len_filter(example):\n",
    "    return len(example.src) <= MAX_LEN and len(example.tgt) <= MAX_LEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dummy number reversal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/toy_reverse/train/data.txt'\n",
    "dev_path = 'data/toy_reverse/dev/data.txt'\n",
    "\n",
    "src = torchtext.data.Field(\n",
    "    batch_first=True, \n",
    "    include_lengths=True\n",
    "    )\n",
    "tgt = torchtext.data.Field(\n",
    "    batch_first=True, \n",
    "    preprocessing = lambda seq: [SOS_TOKEN] + seq + [EOS_TOKEN]\n",
    "    )\n",
    "\n",
    "data_train = torchtext.data.TabularDataset(\n",
    "        path=train_path, format='tsv',\n",
    "        fields=[('src', src), ('tgt', tgt)],\n",
    "        filter_pred=len_filter\n",
    "    )\n",
    "data_dev = torchtext.data.TabularDataset(\n",
    "        path=dev_path, format='tsv',\n",
    "        fields=[('src', src), ('tgt', tgt)],\n",
    "        filter_pred=len_filter\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the e2e data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_BABY = False\n",
    "\n",
    "def comma_split(item):\n",
    "    return [x.strip() for x in item.split(',')]\n",
    "\n",
    "if USE_BABY:\n",
    "    train_path = 'data/e2e-dataset/baby-train.csv'\n",
    "    dev_path = 'data/e2e-dataset/baby-dev.csv'\n",
    "else:\n",
    "    train_path = 'data/e2e-dataset/trainset.csv'\n",
    "    dev_path = 'data/e2e-dataset/devset.csv'\n",
    "\n",
    "src = torchtext.data.Field(\n",
    "    batch_first=True, \n",
    "    include_lengths=True,\n",
    "    tokenize=comma_split\n",
    "    )\n",
    "tgt = torchtext.data.Field(\n",
    "    batch_first=True, \n",
    "    preprocessing = lambda seq: [SOS_TOKEN] + seq + [EOS_TOKEN]\n",
    "    )\n",
    "\n",
    "data_train = torchtext.data.TabularDataset(\n",
    "        path=train_path, format='csv',\n",
    "        fields=[('src', src), ('tgt', tgt)],\n",
    "        filter_pred=len_filter,\n",
    "        skip_header=True\n",
    "    )\n",
    "data_dev = torchtext.data.TabularDataset(\n",
    "        path=dev_path, format='csv',\n",
    "        fields=[('src', src), ('tgt', tgt)],\n",
    "        filter_pred=len_filter,\n",
    "        skip_header=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 tokens from input vocab:\n",
      " ['<unk>', '<pad>', 'familyFriendly[yes]', 'area[riverside]', 'eatType[coffee shop]', 'familyFriendly[no]', 'area[city centre]', 'eatType[pub]', 'food[Japanese]', 'food[Italian]', 'food[Fast food]', 'food[French]', 'priceRange[moderate]', 'priceRange[less than £20]', 'customer rating[average]', 'customer rating[low]', 'priceRange[high]', 'customer rating[5 out of 5]', 'priceRange[more than £30]', 'food[Indian]']\n",
      "\n",
      "20 tokens from output vocab:\n",
      " ['<unk>', '<pad>', 'is', '<eos>', '<sos>', 'a', 'The', 'the', 'in', 'near', 'of', 'and', 'food', 'customer', 'located', 'It', 'restaurant', 'has', 'coffee', 'price']\n",
      "\n",
      "num training examples: 42037\n",
      "\n",
      "example train data:\n",
      "src:\n",
      " ['name[The Waterman]', 'food[Indian]', 'priceRange[high]', 'customer rating[1 out of 5]', 'area[city centre]', 'familyFriendly[yes]']\n",
      "tgt:\n",
      " ['<sos>', 'The', 'Waterman', 'Indian', 'food', 'has', 'a', 'low', 'customer', 'rating', 'and', 'a', 'family', 'friendly', 'environment', 'with', 'a', 'central', 'location', 'and', 'high', 'price', 'range', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "src.build_vocab(data_train, max_size=50000)\n",
    "tgt.build_vocab(data_train, max_size=50000)\n",
    "input_vocab = src.vocab\n",
    "output_vocab = tgt.vocab\n",
    "\n",
    "print('20 tokens from input vocab:\\n', list(input_vocab.stoi.keys())[:20])\n",
    "print('\\n20 tokens from output vocab:\\n', list(output_vocab.stoi.keys())[:20])\n",
    "\n",
    "print('\\nnum training examples:', len(data_train.examples))\n",
    "\n",
    "item = random.choice(data_train.examples)\n",
    "print('\\nexample train data:')\n",
    "print('src:\\n', item.src)\n",
    "print('tgt:\\n', item.tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition and training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, myinput, hidden):\n",
    "        embedded = self.embedding(myinput).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=mydevice)\n",
    "\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=mydevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion,\n",
    "          max_length=MAX_LEN, teacher_forcing_ratio=0.5):\n",
    "    \n",
    "    # get an initial hidden state for the encoder\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    # zero the gradients of the optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # get the seq lengths, used for iterating through encoder/decoder\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    # create empty tensor to fill with encoder outputs\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=mydevice)\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    # pass the inputs through the encoder\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    # create a start-of-sequence tensor for the decoder\n",
    "    decoder_input = torch.tensor([[output_vocab.stoi[SOS_TOKEN]]], device=mydevice)\n",
    "\n",
    "    # set the decoder hidden state to the final encoder hidden state\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        \n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()\n",
    "                \n",
    "        loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
    "        \n",
    "        if use_teacher_forcing:\n",
    "            decoder_input = target_tensor[di]\n",
    "        \n",
    "        if decoder_input.item() == output_vocab.stoi[EOS_TOKEN]:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, learning_rate=0.01, teacher_forcing_ratio=0.5):\n",
    "    print(f'Running {n_iters} epochs...')\n",
    "    print_loss_total = 0\n",
    "    print_loss_epoch = 0\n",
    "\n",
    "    encoder_optim = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optim = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    batch_iterator = torchtext.data.Iterator(\n",
    "        dataset=data_train, batch_size=1,\n",
    "        sort=False, sort_within_batch=True,\n",
    "        sort_key=lambda x: len(x.src),\n",
    "        device=mydevice, repeat=False)\n",
    "    \n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for e in range(n_iters):\n",
    "        batch_generator = batch_iterator.__iter__()\n",
    "        step = 0\n",
    "        start = time.time()\n",
    "        for batch in batch_generator:\n",
    "            step += 1\n",
    "            \n",
    "            # get the input and target from the batch iterator\n",
    "            input_tensor, input_lengths = getattr(batch, 'src')\n",
    "            target_tensor = getattr(batch, 'tgt')\n",
    "            \n",
    "            input_tensor = input_tensor[0]\n",
    "            target_tensor = target_tensor[0]\n",
    "\n",
    "            loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optim, decoder_optim, criterion, teacher_forcing_ratio=teacher_forcing_ratio)\n",
    "            print_loss_total += loss\n",
    "            print_loss_epoch += loss\n",
    "            \n",
    "\n",
    "            if step % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                t = (time.time() - start) / 60\n",
    "                print(f'step: {step}\\t avg loss: {print_loss_avg:.2f}\\t time for {print_every} steps: {t:.2f} min')\n",
    "                start = time.time()\n",
    "        \n",
    "        print_loss_avg = print_loss_epoch / step\n",
    "        print_loss_epoch = 0\n",
    "        print(f'End of epoch {e}, avg loss {print_loss_avg:.2f}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create and train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "encoder1 = EncoderRNN(len(input_vocab), hidden_size).to(mydevice)\n",
    "decoder1 = DecoderRNN(hidden_size, len(output_vocab)).to(mydevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 100 epochs...\n",
      "End of epoch 0, avg loss 4.06\n",
      "End of epoch 1, avg loss 4.10\n",
      "End of epoch 2, avg loss 3.73\n",
      "End of epoch 3, avg loss 3.84\n",
      "End of epoch 4, avg loss 3.78\n",
      "End of epoch 5, avg loss 3.47\n",
      "End of epoch 6, avg loss 3.40\n",
      "End of epoch 7, avg loss 3.27\n",
      "End of epoch 8, avg loss 2.38\n",
      "End of epoch 9, avg loss 2.49\n",
      "End of epoch 10, avg loss 2.65\n",
      "End of epoch 11, avg loss 2.93\n",
      "End of epoch 12, avg loss 2.60\n",
      "End of epoch 13, avg loss 2.54\n",
      "End of epoch 14, avg loss 2.20\n",
      "End of epoch 15, avg loss 2.15\n",
      "End of epoch 16, avg loss 2.00\n",
      "End of epoch 17, avg loss 2.34\n",
      "End of epoch 18, avg loss 2.01\n",
      "End of epoch 19, avg loss 2.02\n",
      "End of epoch 20, avg loss 1.86\n",
      "End of epoch 21, avg loss 1.71\n",
      "End of epoch 22, avg loss 2.49\n",
      "End of epoch 23, avg loss 2.04\n",
      "End of epoch 24, avg loss 2.19\n",
      "End of epoch 25, avg loss 2.04\n",
      "End of epoch 26, avg loss 1.35\n",
      "End of epoch 27, avg loss 1.96\n",
      "End of epoch 28, avg loss 1.59\n",
      "End of epoch 29, avg loss 1.41\n",
      "End of epoch 30, avg loss 1.25\n",
      "End of epoch 31, avg loss 1.22\n",
      "End of epoch 32, avg loss 1.09\n",
      "End of epoch 33, avg loss 1.30\n",
      "End of epoch 34, avg loss 1.57\n",
      "End of epoch 35, avg loss 1.99\n",
      "End of epoch 36, avg loss 2.28\n",
      "End of epoch 37, avg loss 1.69\n",
      "End of epoch 38, avg loss 0.83\n",
      "End of epoch 39, avg loss 1.50\n",
      "End of epoch 40, avg loss 1.10\n",
      "End of epoch 41, avg loss 1.16\n",
      "End of epoch 42, avg loss 1.15\n",
      "End of epoch 43, avg loss 1.81\n",
      "End of epoch 44, avg loss 0.62\n",
      "End of epoch 45, avg loss 0.55\n",
      "End of epoch 46, avg loss 0.83\n",
      "End of epoch 47, avg loss 0.49\n",
      "End of epoch 48, avg loss 0.92\n",
      "End of epoch 49, avg loss 0.45\n",
      "End of epoch 50, avg loss 1.28\n",
      "End of epoch 51, avg loss 1.46\n",
      "End of epoch 52, avg loss 1.20\n",
      "End of epoch 53, avg loss 0.42\n",
      "End of epoch 54, avg loss 0.59\n",
      "End of epoch 55, avg loss 0.37\n",
      "End of epoch 56, avg loss 0.59\n",
      "End of epoch 57, avg loss 0.33\n",
      "End of epoch 58, avg loss 0.30\n",
      "End of epoch 59, avg loss 0.27\n",
      "End of epoch 60, avg loss 0.25\n",
      "End of epoch 61, avg loss 0.24\n",
      "End of epoch 62, avg loss 0.48\n",
      "End of epoch 63, avg loss 1.57\n",
      "End of epoch 64, avg loss 0.27\n",
      "End of epoch 65, avg loss 0.23\n",
      "End of epoch 66, avg loss 0.21\n",
      "End of epoch 67, avg loss 0.43\n",
      "End of epoch 68, avg loss 0.21\n",
      "End of epoch 69, avg loss 0.18\n",
      "End of epoch 70, avg loss 0.17\n",
      "End of epoch 71, avg loss 0.16\n",
      "End of epoch 72, avg loss 0.15\n",
      "End of epoch 73, avg loss 0.14\n",
      "End of epoch 74, avg loss 0.14\n",
      "End of epoch 75, avg loss 0.13\n",
      "End of epoch 76, avg loss 0.13\n",
      "End of epoch 77, avg loss 0.12\n",
      "End of epoch 78, avg loss 0.12\n",
      "End of epoch 79, avg loss 0.11\n",
      "End of epoch 80, avg loss 0.11\n",
      "End of epoch 81, avg loss 0.10\n",
      "End of epoch 82, avg loss 0.10\n",
      "End of epoch 83, avg loss 0.09\n",
      "End of epoch 84, avg loss 0.09\n",
      "End of epoch 85, avg loss 0.09\n",
      "End of epoch 86, avg loss 0.08\n",
      "End of epoch 87, avg loss 0.08\n",
      "End of epoch 88, avg loss 0.08\n",
      "End of epoch 89, avg loss 0.08\n",
      "End of epoch 90, avg loss 0.07\n",
      "End of epoch 91, avg loss 0.07\n",
      "End of epoch 92, avg loss 0.07\n",
      "End of epoch 93, avg loss 0.07\n",
      "End of epoch 94, avg loss 0.07\n",
      "End of epoch 95, avg loss 0.06\n",
      "End of epoch 96, avg loss 0.06\n",
      "End of epoch 97, avg loss 0.06\n",
      "End of epoch 98, avg loss 0.06\n",
      "End of epoch 99, avg loss 0.06\n"
     ]
    }
   ],
   "source": [
    "trainIters(encoder1, decoder1, 100, print_every=1000, teacher_forcing_ratio=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_path = 'saved-models/gpu-encoder1-e2e-1epoch.mdl'\n",
    "dec_path = 'saved-models/gpu-decoder1-e2e-1epoch.mdl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py37/lib/python3.7/site-packages/torch-1.2.0-py3.7-macosx-10.9-x86_64.egg/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type EncoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/anaconda3/envs/py37/lib/python3.7/site-packages/torch-1.2.0-py3.7-macosx-10.9-x86_64.egg/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type DecoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(encoder1, enc_path)\n",
    "torch.save(decoder1, dec_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1 = torch.load(enc_path)\n",
    "decoder1 = torch.load(dec_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LEN):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.tensor([input_vocab.stoi[word] for word in sentence], device=mydevice)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=mydevice)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[output_vocab.stoi[SOS_TOKEN]]], device=mydevice)\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            next_word = output_vocab.itos[topi.item()]\n",
    "            decoded_words.append(next_word)\n",
    "            if next_word == EOS_TOKEN:\n",
    "                break\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implement beam search evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name[The Eagle]', 'eatType[coffee shop]', 'food[Fast food]', 'priceRange[moderate]', 'customer rating[1 out of 5]', 'area[riverside]', 'familyFriendly[no]', 'near[Burger King]']\n",
      "\n",
      "greedy:\n",
      "<sos> The Eagle coffee shop is a fast food coffee shop near Burger King and has a moderate price range and a 1 out of of 5 customer rating. <eos>\n",
      "\n",
      "beam:\n",
      "-0.8448 <sos> The Eagle is a fast food coffee shop located near Burger King in riverside. It has a moderate price range and a customer rating of 1 out of 5. It is not kid friendly and has a moderate price range and a moderate price range and a moderate price range\n",
      "-0.8430 <sos> The Eagle is a fast food coffee shop located near Burger King in riverside. It has a moderate price range and a customer rating of 1 out of 5. It is not kid friendly and has a moderate price range and a moderate price range and a moderate price range.\n",
      "-0.8338 <sos> The Eagle is a fast food coffee shop located near Burger King in riverside. It has a moderate price range and a customer rating of 1 out of 5. It is not kid friendly and has a moderate price range and a moderate price range and a 1 out of\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_with_beam(encoder, decoder, sentence, k=3, max_length=MAX_LEN):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.tensor([input_vocab.stoi[word] for word in sentence], device=mydevice)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=mydevice)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "        \n",
    "        sos = output_vocab.stoi[SOS_TOKEN]\n",
    "        # take first step in decoding\n",
    "        decoder_input = torch.tensor([[sos]], device=mydevice)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.data.topk(k)\n",
    "\n",
    "        k_sequences = [[i] for i in topi[0].tolist()]  # will be lists of sequences of word indeces\n",
    "        k_scores = [[i] for i in topv[0].tolist()]  # will be lists of scores for each word in each seq\n",
    "        k_hidden = [decoder_hidden]*k  # will be the hidden states of each sequence\n",
    "        \n",
    "        for di in range(max_length):\n",
    "            \n",
    "            if all(output_vocab.itos[k_seq[-1]] == EOS_TOKEN for k_seq in k_sequences):\n",
    "                break\n",
    "\n",
    "            k_sequences_new = []\n",
    "            k_scores_new = []\n",
    "            k_hidden_new = []\n",
    "            \n",
    "            for ki, k_seq in enumerate(k_sequences):\n",
    "                if output_vocab.itos[k_seq[-1]] == EOS_TOKEN:\n",
    "                    continue\n",
    "                \n",
    "                decoder_input = torch.tensor([[k_seq[-1]]], device=mydevice)\n",
    "                decoder_hidden = k_hidden[ki]\n",
    "                \n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                \n",
    "                topv, topi = decoder_output.data.topk(k)\n",
    "                \n",
    "                k_sequences_new += [k_seq + [i] for i in topi[0].tolist()]\n",
    "                k_scores_new += [k_scores[ki] + [i] for i in topv[0].tolist()] \n",
    "                k_hidden_new += [decoder_hidden]*k\n",
    "            \n",
    "            k_scores_overall = [sum(k_score)/len(k_score) for k_score in k_scores_new]\n",
    "            topk = sorted(range(len(k_scores_overall)), key=lambda i: k_scores_overall[i])[-k:]\n",
    "\n",
    "            k_sequences = [k_sequences_new[i] for i in topk]\n",
    "            k_scores = [k_scores_new[i] for i in topk]\n",
    "            k_hidden = [k_hidden_new[i] for i in topk]\n",
    "\n",
    "    final_scores = [sum(k_score)/len(k_score) for k_score in k_scores]\n",
    "    \n",
    "    decoded_words = []\n",
    "    for k_seq in k_sequences:\n",
    "        decoded_words.append([output_vocab.itos[i] for i in k_seq])\n",
    "    \n",
    "    return decoded_words, final_scores\n",
    "\n",
    "item = random.choice(data_train.examples)\n",
    "seq = item.src\n",
    "print(seq)\n",
    "\n",
    "output = ' '.join(evaluate(encoder1, decoder1, seq))\n",
    "print(f'\\ngreedy:\\n{output}')\n",
    "\n",
    "k_words, k_scores = evaluate_with_beam(encoder1, decoder1, seq, k=3)\n",
    "print('\\nbeam:')\n",
    "for words, score in zip(k_words, k_scores):\n",
    "    output = ' '.join(words)\n",
    "    print(f'{score:.4f} {output}')\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Implement BLEU evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def get_ngrams(sent, n):\n",
    "    sent = sent.lower()\n",
    "    tokens = [t for t in sent.split(' ') if t != '']\n",
    "    ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "    return [\" \".join(ngram) for ngram in ngrams]\n",
    "    \n",
    "    \n",
    "def modified_precision(refs, candidate):\n",
    "    \"\"\"\n",
    "    assumes refs and candidate are lists of strings of desired ngram.\n",
    "    refs is list of lists of strings.\n",
    "    candidate is list of strings.\n",
    "    \"\"\"\n",
    "    cand_counts = {}\n",
    "    ref_counters = [Counter(ref) for ref in refs]\n",
    "    \n",
    "    for ngram in set(candidate):\n",
    "        count = 0\n",
    "        for ref_c in ref_counters:\n",
    "            if ref_c[ngram] > count:\n",
    "                count = ref_c[ngram]\n",
    "        cand_counts[ngram] = count\n",
    "    \n",
    "    final_count = 0\n",
    "    for ngram in cand_counts:\n",
    "        final_count += min(candidate.count(ngram), cand_counts[ngram])\n",
    "\n",
    "    return final_count / len(candidate)\n",
    "        \n",
    "                \n",
    "def geo_mean(refs, candidate, n=4):\n",
    "    \"\"\"assumes refs and candidate are strings (refs is list of strings)\"\"\"\n",
    "    geomean = 0\n",
    "    for i in range(1, n+1):\n",
    "        refs_n = [get_ngrams(ref, i) for ref in refs]\n",
    "        cand_n = get_ngrams(candidate, i)\n",
    "        p = modified_precision(refs_n, cand_n)\n",
    "        if p == 0:\n",
    "            break\n",
    "        geomean += np.log(p)\n",
    "    \n",
    "    return np.exp((1/i) * geomean)\n",
    "\n",
    "def brev_pen(refs, candidate):\n",
    "    \"\"\"assumes refs and candidate are strings (refs is list of strings)\"\"\"\n",
    "    diffs = []\n",
    "    hyp_len = len(candidate.lower().split(' '))\n",
    "    for ref in refs:\n",
    "        r = ref.lower().split(\" \")\n",
    "        diffs.append(abs(len(r) - hyp_len))\n",
    "    closest_ref_len = len(refs[diffs.index(min(diffs))].split(' '))\n",
    "    if hyp_len > closest_ref_len:\n",
    "        return 1\n",
    "    elif hyp_len == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.exp(1 - (closest_ref_len / hyp_len))\n",
    "\n",
    "def bleu(refs, candidate):\n",
    "    \"\"\"assumes refs and candidate are strings (refs is list of strings)\"\"\"\n",
    "    geomean = geo_mean(refs, candidate)\n",
    "    bp = brev_pen(refs, candidate)\n",
    "    return bp * geomean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU for greedy decoding: 0.4537\n",
      "BLEU for beam search: 0.3389\n"
     ]
    }
   ],
   "source": [
    "seqs = [data_dev.examples[0].src]\n",
    "refs = [[' '.join(data_dev.examples[0].tgt)]]\n",
    "for ex in data_dev.examples[1:]:\n",
    "    if ex.src == seqs[-1]:\n",
    "        refs[-1].append(' '.join(ex.tgt))\n",
    "    else:\n",
    "        seqs.append(ex.src)\n",
    "        refs.append([' '.join(ex.tgt)])\n",
    "\n",
    "        \n",
    "bleu_scores_gr = []\n",
    "bleu_scores_bm = []\n",
    "for seq, rf in zip(seqs, refs):\n",
    "    greedy = ' '.join(evaluate(encoder1, decoder1, seq))\n",
    "    output, scores = evaluate_with_beam(encoder1, decoder1, seq, k=3)\n",
    "    beam = ' '.join(output[scores.index(max(scores))])\n",
    "    bleu_scores_gr.append(bleu(rf, greedy))\n",
    "    bleu_scores_bm.append(bleu(rf, beam))\n",
    "\n",
    "print(f'BLEU for greedy decoding: {sum(bleu_scores_gr)/len(seqs):.4f}')\n",
    "print(f'BLEU for beam search: {sum(bleu_scores_bm)/len(seqs):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REFS:\n",
      "<sos> An average customer rated restaurant that is also child-friendly is The Wrestlers. <eos>\n",
      "<sos> Looking for a family friendly venue with an average customer rating, then you need to check out The Wrestlers. <eos>\n",
      "<sos> The Wrestlers has average Rating and is family-Friendly. <eos>\n",
      "<sos> The Wrestlers has an average customer rating and is also children friendly. <eos>\n",
      "<sos> The Wrestlers is children friendly and has an average rating <eos>\n",
      "<sos> The Wrestlers is an average rated child friendly place. <eos>\n",
      "<sos> The Wrestlers is an average family friendly place. <eos>\n",
      "<sos> One family friendly venue is The Wrestlers. It is averagely rated. Near Café Rouge is a Japanese, family friendly place called The Golden Curry. It is riverside and has high customer ratings. <eos>\n",
      "<sos> A nice place to take the family is The Wrestlers. <eos>\n",
      "<sos> An average restaurant named The Wrestlers is children friendly. <eos>\n",
      "<sos> The Wrestlers is an average, family friendly venue. Near Café Rouge is a Japanese, family friendly place called The Golden Curry. It is riverside and has high customer ratings. <eos>\n",
      "<sos> The Wrestlers has an average rating and is children friendly <eos>\n",
      "<sos> The Wrestlers is a child friendly venue with an average rating. <eos>\n",
      "<sos> The Wrestlers restaurant has an average customer rating and is children-friendly. <eos>\n",
      "<sos> The Wrestlers is an average family friendly place. <eos>\n",
      "<sos> The Wrestlers is a decent family-friendly place. <eos>\n",
      "<sos> The Wrestlers is an average restaurant that is children friendly. <eos>\n",
      "<sos> The Wrestlers is an average child friendly venue. <eos>\n",
      "<sos> The Wrestlers is a family friendly venue with an average customer rating. <eos>\n",
      "<sos> The Wrestlers is children friendly and has an average customer rating. <eos>\n",
      "<sos> The Wrestlers is family friendly and has an average customer rating. <eos>\n",
      "<sos> Families are welcome at The Wrestlers. <eos>\n",
      "<sos> The Wrestlers is a family friendly environment with an average rating. <eos>\n",
      "<sos> A family place is The Wrestlers although it is only average. <eos>\n",
      "GR: 0.5806 <sos> The Wrestlers is a family friendly restaurant restaurant serving Indian food. It has an average customer rating and is <eos>\n",
      "BM: 0.2788 <sos> There is a family friendly restaurant called The Waterman. It has an average customer rating and serves cheap food and average prices. It is located in the city centre. <eos>\n",
      "\n",
      "REFS:\n",
      "<sos> Wildwood is a Chinese coffee shop with an average rating. It has a cheap price range and is located near the Ranch. <eos>\n",
      "<sos> The average rated Wildwood coffee shop has cheap Chinese food and is near the Ranch. <eos>\n",
      "<sos> Near the Ranch there is a cheap coffee shop that serves Chinese food named Wildwood and has an average rating. <eos>\n",
      "<sos> There is a cheap Chinese coffee shop called Wildwood. It is near the Ranch and has an average customer rating. <eos>\n",
      "<sos> Wildwood is a coffee shop providing Chinese food in the cheap price range. It is near Ranch. Its customer rating is average. <eos>\n",
      "<sos> Wildwood is a coffee shop providing Chinese food in the cheap price range. It is near Ranch. Its customer rating is average. <eos>\n",
      "GR: 0.6566 <sos> Wildwood is a coffee shop near Ranch with a cheap price range and an average customer rating. <eos>\n",
      "BM: 0.3165 <sos> Wildwood is a cheap coffee shop near Ranch with an average customer rating. It is located in the city centre near to Burger King. It is located in the city centre. <eos>\n",
      "\n",
      "REFS:\n",
      "<sos> The Punter is a coffee shop near Café Sicilia offering Chinese food for less than 20 Euros but it has a low customer rating. It is not family-friendly. <eos>\n",
      "<sos> Near Café Sicilia is The Punter. It is a Chinese coffee shop with a lower price range but the customer rating is low and it is not kid-friendly. <eos>\n",
      "<sos> The Punter is a coffee shop providing Chinese food in the less than £20 price range. It is near Café Sicilia. Its customer rating is low. <eos>\n",
      "<sos> the coffee shop The Punter near Café Sicilia serves Chinese food with a price range of less than 20 pounds. It is not family friendly and has a low customer rating. <eos>\n",
      "<sos> near Café Sicilia there's a low customer rated coffee shop that serves Chinese food with a price range of less than 20 pounds called The Punter. <eos>\n",
      "<sos> The Punter is a coffee shop providing Chinese food in the less than £20 price range. It is near Café Sicilia. Its customer rating is low. <eos>\n",
      "GR: 0.2104 <sos> The Punter is a low rated restaurant serving fast food and is located near Café Sicilia and is not Sicilia <eos>\n",
      "BM: 0.2982 <sos> The Punter is a near Café Sicilia Café Sicilia Sicilia a low price range and not family friendly. It has a low customer rating and serves fast food and a low customer rating. It has a low customer rating and has a low customer rating and is not family-friendly. <eos>\n",
      "\n",
      "REFS:\n",
      "<sos> Near Raja Indian Cuisine by riverside there is an English coffee shop called The Wrestlers. It has prices lower than £20 and is family friendly. <eos>\n",
      "<sos> The Wrestlers, a low price family friendly breakfast and coffee shop near Raja Indian Cuisine. <eos>\n",
      "<sos> The Wrestlers is a family friendly coffee shop with prices less that £20. This English coffee shop is located by riverside near Raja Indian Cuisine. <eos>\n",
      "<sos> The Wrestlers is a low-priced family coffee shop located near Raja Indian Cuisine in City Centre <eos>\n",
      "<sos> Visit The Wrestlers, a low priced family friendly breakfast and coffee shop located near Raja Indian Cuisine. <eos>\n",
      "<sos> There is an inexpensive and family friendly coffee shop serving English fare near Raja Indian Cuisine in riverside called The Wrestlers. <eos>\n",
      "<sos> The Wrestlers coffee shop offers a family friendly environment with a price range of less than £20. We offer English food near Raja Indian Cuisine in the riverside area. <eos>\n",
      "<sos> There is a family friendly coffee shop located near Raja Indian Cuisine in the city centre called The Wrestlers which offers cheap food. <eos>\n",
      "<sos> For under £20 you can eat at The Wrestlers in riverside. It's a family friendly coffee shop near Raja Indian Cuisine that serves English cuisine. <eos>\n",
      "<sos> Come to the riverside area near Raja Indian Cuisine and enjoy our coffee shop here at The Wrestlers. We are family friendly, feature English food and have a price range of less than £20. <eos>\n",
      "<sos> The Wrestlers is a family friendly coffee shop located near Raja Indian Cuisine in the city centre which offers cheap food. <eos>\n",
      "GR: 0.5949 <sos> The Wrestlers is a family friendly coffee shop in the low price range. It is located in the riverside area near Raja Indian <eos>\n",
      "BM: 0.3683 <sos> There is a family friendly coffee shop called The Wrestlers located near Raja Indian Cuisine in the low price range. It is located in the city centre. It offers Indian food. It has a low customer rating and it has a low customer rating and is located in the riverside\n",
      "\n",
      "REFS:\n",
      "<sos> If you're looking for some cheap English food, a coffee shop named The Golden Palace is rated 5 out of 5, you'll find it at the city centre. <eos>\n",
      "<sos> The Golden Palace is an English coffee Shop in the city centre which is cheap in price but has a 5 out of 5 customer rating. <eos>\n",
      "<sos> The Golden Palace is an English coffee shop. It is cheap and has a customer rating of 5 out of 5. You can find it in the city centre. <eos>\n",
      "<sos> The Golden Palace is a great coffee shop selling English food by the city centre. It's 5 out of 5 and you can get a great meal for cheap there. <eos>\n",
      "<sos> The Golden Palace English coffee shop in the city centre has a 5 out of 5 customer rating and is cheap in price. <eos>\n",
      "<sos> The Golden Palace is a cheap English coffee shop located in the city centre, and it has a customer rating of 5 out of 5. <eos>\n",
      "GR: 0.5009 <sos> The Golden Palace is a cheap coffee shop in the city centre city centre serves and has a of the city of 5 out of of 5. <eos>\n",
      "BM: 0.4356 <sos> The Golden Palace is a cheap coffee shop located in the city centre city centre with a low customer rating and a of 5 out of of 5. of the city centre. It offers cheap food. It has a customer rating of 5 out of 5. It is located in\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n=5\n",
    "\n",
    "# for seq, rf in zip(seqs[1:n], refs[1:n]):\n",
    "for _ in range(n):\n",
    "    i = random.choice(range(len(seqs)))\n",
    "    seq = seqs[i]\n",
    "    rf = refs[i]\n",
    "    greedy = ' '.join(evaluate(encoder1, decoder1, seq))\n",
    "    output, scores = evaluate_with_beam(encoder1, decoder1, seq, k=3)\n",
    "    beam = ' '.join(output[scores.index(max(scores))])\n",
    "    b_gr = bleu(rf, greedy)\n",
    "    b_bm = bleu(rf, beam)\n",
    "    print('REFS:')\n",
    "    for r in rf:\n",
    "        print(r)\n",
    "    print(f'GR: {b_gr:.4f} {greedy}')\n",
    "    print(f'BM: {b_bm:.4f} {beam}')\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Beam Search Analysis\n",
    "\n",
    "For greedy decoding the BLEU score was 0.5197. <br>\n",
    "For Beam Search the BLEU scores were as follows:\n",
    "\n",
    "| Beam Size | BLEU Scores |\n",
    "|-----------|-------------|\n",
    "| 5         | 0.5660      |\n",
    "| 10        | 0.5681      |\n",
    "| 15        | 0.5678      |\n",
    "| 20        | 0.5646      |\n",
    "\n",
    "It makes sense that BLEU scores for beam search are higher than the greedy score because greedy is effectively beam search with a size of 1. Since we modeled beam search with sizes 5, 10, 15, and 20, there were many more possibilities considered at each step. Because of this, the output of beam was closer to the true meaning.\n",
    "<br>\n",
    "\n",
    "While the greedy path starts off as the most likely sequence, as the sentence grows and more context is added, it's possible for words that were seemingly \"less likely\" in the beginning have a chance of leading to more probable sentences. Greedy will never be able to capture sentences in those situations, making beam search, which follows multiple paths, a great tool for finding the most probable sentences.\n",
    "<br>\n",
    "\n",
    "However, beam search has the disadvantage of having low BLEU scores with high beam sizes because non optimal solutions are constantly being considered. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. What's wrong with BLEU?\n",
    "\n",
    "BLEU does not consider meaning of words. BLEU scores will only be high if the machine translations and references have exact matches for n-grams. But since it is possible for machine translations to have a valid synonym which is not present in the references, BLEU will be unable to identify the translations as valid.\n",
    "<br>\n",
    "\n",
    "BLEU also does not consider the sentence structure. So it's possible to have a high BLEU score even if the machiine translated sentence is just a random shuffling of the order of words in the reference sentences. This is not ideal since after shuffling the order of words, the machine translated sentence does not actually give a good translation of the input sentence and might even convey a different incorrect meaning, but the high BLEU score would incorrectly make it appear to be a good translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
